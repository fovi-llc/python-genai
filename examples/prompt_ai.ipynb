{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome Built-in AI Demo in JupyterLab and JupyterLite Python Notebook\n",
    "\n",
    "This notebook demonstrates the Python wrapper for Chrome's built-in AI Prompt API.\n",
    "\n",
    "https://developer.chrome.com/docs/ai/prompt-api\n",
    "\n",
    "**Requirements:**\n",
    "- Chrome browser with Prompt API enabled\n",
    "- Running in JupyterLab, Jupyter Notebook, or JupyterLite (statically served, all execution locally in browser)\n",
    "\n",
    "## For developers: Using the Prompt API\n",
    "* Open Chrome and go to `chrome://flags`.\n",
    "* Enable the `#prompt-api-for-gemini-nano` flag.\n",
    "* Enable the `#optimization-guide-on-device-model` flag. If you see a \"BypassPerfRequirement\" option, select it.\n",
    "* Restart Chrome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q anywidget ipywidgets \"wiki3_ai>=0.5.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from wiki3_ai import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b8757985a6483ab77b9913a7aee32f",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModelWidget object at 0xffffa5fdaa50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LanguageModel.widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Availability\n",
    "\n",
    "First, let's check if the Prompt API is available in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'available'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the API is available\n",
    "await LanguageModel.availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Parameters\n",
    "\n",
    "Let's see what parameters the model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default temperature: 1\n",
      "Max temperature: 2\n",
      "Default top-K: 3\n",
      "Max top-K: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'defaultTopK': 3,\n",
       " 'maxTopK': 128,\n",
       " 'defaultTemperature': 1,\n",
       " 'maxTemperature': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = await LanguageModel.params()\n",
    "\n",
    "if params:\n",
    "    print(f\"Default temperature: {params.get(\"defaultTemperature\")}\")\n",
    "    print(f\"Max temperature: {params.get(\"maxTemperature\")}\")\n",
    "    print(f\"Default top-K: {params.get(\"defaultTopK\")}\")\n",
    "    print(f\"Max top-K: {params.get(\"maxTopK\")}\")\n",
    "else:\n",
    "    print(\"Model parameters not available\")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LanguageModel Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModel at 0xffffa55e8980>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = await LanguageModel.create()\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt\n",
    "\n",
    "Create a session and send a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code flows, clean and bright,\n",
      "Indentation guides the way,\n",
      "Logic takes new form. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt\n",
    "result = await lm.prompt(\"Write a haiku about Python programming.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "Use a system prompt to set the context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "with open('your_file.csv', 'r') as file:\n",
      "    reader = csv.reader(file)\n",
      "    for row in reader:\n",
      "        print(row)\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1.  **`import csv`**: Imports the `csv` module.\n",
      "2.  **`with open('your_file.csv', 'r') as file:`**: Opens the CSV file in read mode (`'r'`). The `with` statement ensures the file is properly closed afterward. Replace `'your_file.csv'` with the actual filename.\n",
      "3.  **`reader = csv.reader(file)`**: Creates a `csv.reader` object to iterate over rows in the CSV file.\n",
      "4.  **`for row in reader:`**: Iterates through each row in the CSV file.  `row` is a list of strings representing the values in each cell of that row.\n",
      "5.  **`print(row)`**: Prints each row. You can then process the data in each row as needed.\n",
      "\n",
      "\n",
      "\n",
      "For more complex CSV files (e.g., with headers or different delimiters), explore `csv.DictReader`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a session with a system prompt\n",
    "assistant_session = await LanguageModel.create(\n",
    "    {\n",
    "        \"initialPrompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful Python programming assistant who gives concise answers.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = await assistant_session.prompt(\"How do I read a CSV file in Python?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "def read_csv(filename):\n",
      "  \"\"\"\n",
      "  Reads a CSV file and prints each row.\n",
      "\n",
      "  Args:\n",
      "    filename: The name of the CSV file to read.\n",
      "  \"\"\"\n",
      "  try:\n",
      "    # Open the CSV file in read mode ('r'). The 'with' statement ensures the file is automatically closed.\n",
      "    with open(filename, 'r') as file:\n",
      "      # Create a CSV reader object. This object allows you to iterate over the rows of the CSV file.\n",
      "      reader = csv.reader(file)\n",
      "\n",
      "      # Iterate over each row in the CSV file. Each 'row' is a list of strings, representing the values in each column.\n",
      "      for row in reader:\n",
      "        # Print the row to the console. You can replace this with your desired processing logic.\n",
      "        print(row)\n",
      "  except FileNotFoundError:\n",
      "    print(f\"Error: File '{filename}' not found.\")\n",
      "  except Exception as e:\n",
      "    print(f\"An error occurred: {e}\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = await assistant_session.prompt(\"Please return just the code to read a CSV file in Python.  Include detailed comments.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response\n",
    "\n",
    "Stream the response as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", end=\"\")\n",
    "async for chunk in assistant_session.prompt_streaming(\"Tell me a short joke about computers.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db590092-1b1e-4a98-9f32-db11c73a8759': ['Why',\n",
       "  ' did',\n",
       "  ' the',\n",
       "  ' computer',\n",
       "  ' to',\n",
       "  '?',\n",
       "  ' ',\n",
       "  '\\n\\n',\n",
       "  ' had',\n",
       "  ' too',\n",
       "  ' issues',\n",
       "  '!',\n",
       "  '\\n']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_session.widget()._stream_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n",
    "\n",
    "Have a conversation with context maintained across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: A list comprehension is a concise way to create new lists based on existing iterables (like lists, tuples, or ranges) in Python.  It's a more compact and often faster alternative to using `for` loops to build lists.\n",
      "\n",
      "Example:  `squares = [x**2 for x in range(10)]` creates a list of squares from 0 to 9.\n",
      "\n",
      "Assistant: ```python\n",
      "# Standard loop\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "squares = []\n",
      "for num in numbers:\n",
      "  squares.append(num**2)\n",
      "print(squares)  # Output: [1, 4, 9, 16, 25]\n",
      "\n",
      "# List comprehension\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "squares = [num**2 for num in numbers]\n",
      "print(squares)  # Output: [1, 4, 9, 16, 25]\n",
      "```\n",
      "\n",
      "The list comprehension `[num**2 for num in numbers]` achieves the same result in a single line.\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "result1 = await assistant_session.prompt(\"What is a list comprehension?\")\n",
    "print(\"Assistant:\", result1)\n",
    "print()\n",
    "\n",
    "# Follow-up message (the assistant remembers the context)\n",
    "result2 = await assistant_session.prompt(\"Can you show me an example?\")\n",
    "print(\"Assistant:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Token Usage\n",
    "\n",
    "Monitor how many tokens you've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current usage: 417/9216 tokens\n",
      "\n",
      "This prompt would use approximately 13 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current usage: {assistant_session.input_usage}/{assistant_session.input_quota} tokens\")\n",
    "\n",
    "# Measure how many tokens a prompt would use\n",
    "usage = await assistant_session.measure_input_usage(\"What is machine learning?\")\n",
    "print(f\"\\nThis prompt would use approximately {usage} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Use JSON schema to get structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"sentiment\", \"score\"],\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
    "        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get structured response\n",
    "result = await lm.prompt(\n",
    "    \"Analyze this review: The product exceeded all my expectations! Absolutely amazing!\",\n",
    "    {\"responseConstraint\": schema},\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(result)\n",
    "print(f\"Sentiment: {data['sentiment']}\")\n",
    "print(f\"Score: {data['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Cloning\n",
    "\n",
    "Clone a session to create different conversation branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 1: Once upon a time, there was a dragon. Not a fearsome, fire-breathing terror of legends, mind you. This dragon, whose name was Zephyr, was rather underwhelming. He didn't breathe scorching flames, but puffs of shimmering, lavender-scented smoke. He wasn't armored in scales of obsidian or ruby, but sported a coat of soft, moss-green scales that often caught dew and sparkled in the sunlight. \n",
      "\n",
      "Zephyr lived in a hollowed-out willow tree nestled beside Whisperwind Creek. He spent his days collecting fallen feathers – blue jay feathers, robin feathers, even the iridescent plumage of hummingbirds – and weaving them into elaborate crowns. He didn't hoard gold, but polished pebbles and smooth river stones, arranging them in pleasing patterns around his cozy nest. \n",
      "\n",
      "Zephyr was exceptionally friendly and helpful. The creatures of the forest knew they could always rely on him. When the squirrels' winter stores dwindled, Zephyr gently puffed lavender smoke to stimulate the growth of plump berries. When the baby birds fell from their nests, he’d carefully cradle them in his scaled claws, offering a soothing lavender scent until their mothers could return. He helped lost travelers find their way, not with terrifying roars, but with gentle lavender puffs that guided them towards the path. He’d even use his floppy wings to create a gentle breeze to cool weary travelers on hot days.\n",
      "\n",
      "He guarded Whisperwind Creek, not with fire, but with careful attention. He'd nudge fallen logs away from the flow of water, ensuring the fish had plenty of space to thrive. He’d clear debris from the creek bed, and even coax the shy water lilies to bloom with his gentle lavender smoke. \n",
      "\n",
      "Most importantly, Zephyr wasn’t particularly good at being a dragon. He couldn't roar, only squeak. He couldn't fly with the effortless grace of his kin, his wings were a bit… floppy, leading to a lot of gentle, gliding landings rather than soaring flight. And instead of guarding treasure, he guarded the creek, making sure the water flowed freely and the fish had a plentiful supply of shimmering algae.\n",
      "\n",
      "He longed to be intimidating, to be the majestic beast of stories. But all he really wanted was to make things beautiful, to ease the worries of others. And that, he discovered, wasn't so bad after all. He was Zephyr, the dragon who collected feathers and kept a creek sparkling, a gentle giant in a world expecting a fiery one. And that was perfectly alright.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start a story\n",
    "story_session = await LanguageModel.create(\n",
    "    {\"initialPrompts\": [{\"role\": \"system\", \"content\": \"You are a creative storyteller.\"}]}\n",
    ")\n",
    "\n",
    "await story_session.prompt(\"Once upon a time, there was a dragon.\")\n",
    "\n",
    "# Create two different story branches\n",
    "branch1 = await story_session.clone()\n",
    "branch2 = await story_session.clone()\n",
    "\n",
    "result1 = await branch1.prompt(\"The dragon was friendly and helpful.\")\n",
    "print(\"Branch 1:\", result1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 2: Once upon a time, there was a dragon. But *this* dragon was not like the others. This was Ignis, and terror was not just a part of him – it *was* him. He wasn’t built for shimmering scales and gentle breezes. Ignis was forged from shadow and obsidian, his scales the color of a dying star, etched with veins of molten gold that pulsed with barely contained power.\n",
      "\n",
      "His roar wasn't a rumble, but a seismic tremor that shattered stone and rattled the very foundations of mountains. Smoke poured from his nostrils, not lavender-scented, but acrid and choking, a harbinger of destruction. His wings, vast and leathery, blotted out the sun as he wheeled through the sky, casting the land below into perpetual twilight.\n",
      "\n",
      "Ignis didn’t hoard gold; he *demanded* it. Mountains of it piled high in his cavern, shimmering under the eerie glow of volcanic vents. But gold wasn't his obsession. Power was. The power to command, to destroy, to rule. He’d spent centuries honing his fearsome reputation, crushing kingdoms and extinguishing hope. Villages whispered his name in trembling breaths, and knights dared not look him in the eye.\n",
      "\n",
      "He was a creature of instinct, driven by a primal need to dominate. He craved the thrill of the chase, the satisfaction of crushing defiance, the echoing silence that followed his wrath. He believed that strength was the only virtue, and kindness a weakness to be exploited. He was the embodiment of destruction, the harbinger of doom – a dragon built for one purpose: to instill fear.\n",
      "\n",
      "Ignis surveyed his domain, a jagged landscape scarred by his fiery passage. He wasn't seeking beauty or peace. He was seeking more power, more dominion, more reasons for the world to tremble before him. For Ignis, the terror wasn't just a part of his being; it was the very air he breathed.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = await branch2.prompt(\"The dragon was fierce and terrifying.\")\n",
    "print(\"Branch 2:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Destroy sessions when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sessions destroyed\n"
     ]
    }
   ],
   "source": [
    "await lm.destroy()\n",
    "await assistant_session.destroy()\n",
    "await story_session.destroy()\n",
    "await branch1.destroy()\n",
    "await branch2.destroy()\n",
    "\n",
    "print(\"✅ All sessions destroyed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
